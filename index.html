<!DOCTYPE html>
<html>
<head>
<title>Chen-Yu Lee</title>

<meta name="viewport" content="width=device-width"/>
<meta name="description" content="Chen-Yu Lee."/>
<meta charset="UTF-8"> 

<link type="text/css" rel="stylesheet" href="style.css">
<link href='http://fonts.googleapis.com/css?family=Rokkitt:400,700|Lato:400,300' rel='stylesheet' type='text/css'>
<link rel="shortcut icon" href="favicon.ico" />

<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>
<body id="top">
<div id="cv">
	<div class="mainDetails">
		<div id="headshot">
			<img src="me3.JPG" alt="Chen-Yu Lee" /></a>
		</div>
		
		<div id="name">
			<h2>Chen-Yu Lee</h2><br><br>
			<div id="contactDetails">
				<ul>
					<!--<li align="left"><a href="PDF/ChenYuLee_CV.pdf">CV</a>-->
					<br>
					<li align="left">
						<a href="https://scholar.google.com/citations?user=uWPUSEgAAAAJ&hl=en">Google Scholar</a>
						/
						<a href="mailto:chenyulee260@gmail.com">Email</a>	
				</ul>
			</div>
		</div>
	</div>
	<br><br><br><br><br><br><br>
	<div id="mainArea">
		<section>
			<div class="sectionContent">
				<h4>
					I am currently a Senior Staff Research Scientist and Manager at Google Cloud AI Research, driving innovation in machine learning and its real-world applications across diverse tasks and modalities.<br><br>
				</h4>
				<h5>
					Previously, I was at Apple where I published the Technology Development Group's inaugural research <a href="https://machinelearning.apple.com/2019/06/15/bridging-the-domain-gap-for-neural-models.html">paper</a> at CVPR and launched several key features in <a href="https://developer.apple.com/augmented-reality/arkit/">ARKit</a> (now <a href="https://www.apple.com/apple-vision-pro/">Vision Pro</a>). I was also in the AI Research Group at Magic Leap with <a href="https://scholar.google.com/citations?user=yOcNQVgAAAAJ&hl=en">Andrew Rabinovich</a>. I completed my PhD in deep learning, advised by Professors <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a> and <a href="http://code.ucsd.edu/~pcosman/">Pamela Cosman</a> at UC San Diego, and mentored by <a href="https://scholar.google.com/citations?user=Jq8ZS5kAAAAJ&hl=en">Simon Osindero</a> during my summer research. I am a recipient of the <a href="PDF/tta.jpg">Test-of-Time Award</a> for <a href="https://proceedings.mlr.press/v38/lee15a.pdf">Deep Supervision</a> at <a href="https://virtual.aistats.org/virtual/2025/poster/10054">AISTATS 2025</a> and the <a href="https://research.google/blog/google-at-acl-2023/">Google Spotlight Award</a> for <a href="https://arxiv.org/pdf/2305.02301">Distilling Step-by-Step!</a> at <a href="https://2023.aclweb.org/">ACL 2023</a>.<br><br>
				</h5>
				<h5>
					We are assembling a world-class team to explore the intersection of large AI models and high-value enterprise AI challenges. Contact me to learn more.
				</h5>				
			</div>
		</section>

		<section>
			<div class="sectionTitle">
				<h1>Selected Publications</h1>
			</div>
			
			<div class="sectionContent">
					<h3>Deep Researcher with Test-Time Diffusion</h3>
					Rujun Han, Yanfei Chen, Zoey CuiZhu, Lesly Miculicich, Guan Sun, Yuanjun Bi, Weiming Wen, Hui Wan, Chunfeng Wen, Solène Maître, George Lee, Vishy Tirumalashetty, Emily Xue, Zizhao Zhang, Salem Haykal, Burak Gokturk, Tomas Pfister, Chen-Yu Lee<br>
					<b><a href="https://arxiv.org/">arXiv 2025</a> / </b><a href="https://arxiv.org/pdf/2507.16075">Paper</a> <b>/ <img src="tv.png" width="16" class="align-top">featured by <a href="https://venturebeat.com/ai/googles-new-diffusion-ai-agent-mimics-human-writing-to-improve-enterprise-research/">VentureBeat</a></b> 
					<br><br>

					<h3>Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities</h3>
					Gemini Team, Google<br>
					<b><a href="https://arxiv.org/">arXiv 2025</a> / </b><a href="https://arxiv.org/pdf/2507.06261">Paper</a> 
					<br><br>

					<h3>Towards Compute-Optimal Many-Shot In-Context Learning</h3>
					Shahriar Golchin, Yanfei Chen, Rujun Han, Manan Gandhi, Tianli Yu, Swaroop Mishra, Mihai Surdeanu, Rishabh Agarwal, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://colmweb.org/">COLM 2025</a> / </b><a href="https://arxiv.org/pdf/2507.16217">Paper</a> 
					<br><br>

					<h3>In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents</h3>
					Zhen Tan, Jun Yan, I-Hung Hsu, Rujun Han, Zifeng Wang, Long T. Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, Anand Iyer, Tianlong Chen, Huan Liu, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2025.aclweb.org/">ACL 2025</a> / </b><a href="https://arxiv.org/pdf/2503.08026">Paper</a> 
					<br><br>

					<h3>Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence</h3>
					Shangbin Feng, Zifeng Wang, Yike Wang, Sayna Ebrahimi, Hamid Palangi, Lesly Miculicich, Achin Kulshrestha, Nathalie Rauschmayr, Yejin Choi, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://icml.cc/Conferences/2025">ICML 2025</a> / </b><a href="https://arxiv.org/pdf/2410.11163">Paper</a> 
					<br><br>

					<h3>Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling</h3>
					Wenda Xu, Rujun Han, Zifeng Wang, Long T. Le, Dhruv Madeka, Lei Li, William Yang Wang, Rishabh Agarwal, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> / </b><a href="https://arxiv.org/pdf/2410.11325">Paper</a> <b>/</b> <a href="https://github.com/google-research/google-research/tree/master/speculative_kd">Code</a> 
					<br><br>
									
					<h3>Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting</h3>
					Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo Shang, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> / </b><a href="https://arxiv.org/pdf/2407.08223">Paper</a> <b>/</b> <a href="https://research.google/blog/speculative-rag-enhancing-retrieval-augmented-generation-through-drafting/">Google AI Blog</a>
					<br><br>

					<h3>Reverse Thinking Makes LLMs Stronger Reasoners</h3>
					Justin Chih-Yao Chen, Zifeng Wang, Hamid Palangi, Rujun Han, Sayna Ebrahimi, Long Le, Vincent Perot, Swaroop Mishra, Mohit Bansal, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2025.naacl.org/">NAACL 2025</a> / </b><a href="https://arxiv.org/abs/2411.19865">Paper</a> <b>/</b> <a href="https://github.com/google-research/google-research/tree/master/RevThink">Code</a>
					<br><br>					
									
					<h3>Where is the answer? An empirical study of positional bias for parametric knowledge extraction in language model</h3>
					Kuniaki Saito, Chen-Yu Lee, Kihyuk Sohn, Yoshitaka Ushiku<br>
					<b><a href="https://2025.naacl.org/">NAACL 2025</a> / </b><a href="https://aclanthology.org/2025.naacl-long.58.pdf">Paper</a> <h6>(Oral Presentation)</h6>
					<br><br>

					<h3>TableRAG: Million-Token Tabular Reasoning with Large Language Models</h3>
					Si-An Chen, Lesly Miculicich, Julian Martin Eisenschlos, Zifeng Wang, Zilong Wang, Yanfei Chen, Yasuhisa Fujii, Hsuan-Tien Lin, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://neurips.cc/Conferences/2024">NeurIPS 2024</a> / </b><a href="https://arxiv.org/pdf/2410.04739">Paper</a> <b>/</b> <a href="https://github.com/google-research/google-research/tree/master/table_rag">Code</a> 
					<br><br>

					<h3>Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval</h3>
					Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2024.emnlp.org/">EMNLP 2024</a> / </b><a href="https://arxiv.org/pdf/2408.01875">Paper</a> (Findings) <b>/</b> <a href="https://research.google/blog/re-invoke-tool-invocation-rewriting-for-zero-shot-tool-retrieval/">Google AI Blog</a>
					<br><br>

					<h3>CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation</h3>
					I-Hung Hsu, Zifeng Wang, Long T. Le, Lesly Miculicich, Nanyun Peng, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2024.aclweb.org/">ACL 2024</a> / </b><a href="https://arxiv.org/pdf/2406.05365">Paper</a> (Findings)
					<br><br>

					<h3>Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization</h3>
					Cheng-Yu Hsieh, Yung-Sung Chuang, Chun-Liang Li, Zifeng Wang, Long Le, Abhishek Kumar, James R. Glass, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister<br>
					<b><a href="https://2024.aclweb.org/">ACL 2024</a> / </b><a href="https://arxiv.org/pdf/2406.16008">Paper</a> (Findings)
					<br><br>

					<h3>LMDX: Language Model-based Document Information Extraction and Localization</h3>
					Vincent Perot, Kai Kang, Florian Luisier, Guolong Su, Xiaoyu Sun, Ramya Sree Boppana, Zilong Wang, Zifeng Wang, Jiaqi Mu, Hao Zhang, Chen-Yu Lee, Nan Hua<br>
					<b><a href="https://2024.aclweb.org/">ACL 2024</a> / </b><a href="https://arxiv.org/pdf/2309.10952">Paper</a> (Findings)
					<br><br>									

					<h3>CodecLM: Aligning Language Models with Tailored Synthetic Data</h3>
					Zifeng Wang, Chun-Liang Li, Vincent Perot, Long T. Le, Jin Miao, Zizhao Zhang, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2024.naacl.org">NAACL 2024</a> / </b><a href="https://arxiv.org/pdf/2404.05875.pdf">Paper</a> (Findings) <b>/</b> <a href="https://research.google/blog/codeclm-aligning-language-models-with-tailored-synthetic-data/">Google AI Blog</a>
					<br><br>	

					<h3>Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding</h3>
					Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://iclr.cc/Conferences/2024">ICLR 2024</a> / </b><a href="https://arxiv.org/pdf/2401.04398.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/chain-of-table">Code</a> <b>/</b> <a href="https://blog.research.google/2024/03/chain-of-table-evolving-tables-in.html">Google AI Blog</a>
					<br><br>					

					<h3>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</h3>
					Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2305.02301.pdf">Paper</a> (Findings) <b>/</b> <a href="https://github.com/google-research/distilling-step-by-step">Code</a> <b>/</b> <a href="https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html">Google AI Blog</a> <b><a href="https://blog.research.google/2023/07/google-at-acl-2023.html"><h6>(Google ACL 2023 Spotlight)</h6></a></b>
					<br><br>

					<h3>QueryForm: A Simple Zero-shot Form Entity Query Framework</h3>
					Zifeng Wang, Zizhao Zhang, Jacob Devlin, Chen-Yu Lee, Guolong Su, Hao Zhang, Jennifer Dy, Vincent Perot, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2211.07730.pdf">Paper</a> (Findings)
					<br><br>

					<h3>FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Hao Zhang, Timothy Dozat, Vincent Perot, Guolong Su, Xiang Zhang, Kihyuk Sohn, Nikolai Glushnev, Renshen Wang, Joshua Ainslie, Shangbang Long, Siyang Qin, Yasuhisa Fujii, Nan Hua, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2305.02549.pdf">Paper</a>
					<br><br>									

					<h3>VRDU: A Benchmark for Visually-rich Document Understanding</h3>
					Zilong Wang, Yichao Zhou, Wei Wei, Chen-Yu Lee, Sandeep Tata<br>
					<b><a href="https://kdd.org/kdd2023/">KDD 2023</a> / </b><a href="https://arxiv.org/pdf/2211.15421.pdf">Paper</a>  <b>/</b> <a href="https://github.com/google-research/google-research/tree/master/vrdu">Code</a>  <b>/</b> <a href="https://github.com/google-research-datasets/vrdu">Dataset</a>
					<br><br>
					
					<h3>Multimodal Prompting with Missing Modalities for Visual Recognition</h3>
					Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu, Chen-Yu Lee<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2303.03369.pdf">Paper</a> <b>/</b> <a href="https://github.com/YiLunLee/Missing_aware_prompts">Code</a>
					<br><br>

					<h3>Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image Retrieval</h3>
					Kuniaki Saito, Kihyuk Sohn, Xiang Zhang, Chun-Liang Li, Chen-Yu Lee, Kate Saenko, Tomas Pfister<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2302.03084.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/composed_image_retrieval">Code</a>  <b>/</b> <a href="https://blog.research.google/2023/07/pic2word-mapping-pictures-to-words-for.html">Google AI Blog</a>
					<br><br>

					<h3>Prefix Conditioning Unifies Language and Label Supervision</h3>
					Kuniaki Saito, Kihyuk Sohn, Xiang Zhang, Chun-Liang Li, Chen-Yu Lee, Kate Saenko, Tomas Pfister<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2206.01125.pdf">Paper</a>  <b>/</b> <a href="https://blog.research.google/2023/06/unifying-image-caption-and-image.html">Google AI Blog</a>
					<br><br>

					<h3>DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</h3>
					Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, Tomas Pfister<br>
					<b><a href="https://eccv2022.ecva.net/">ECCV 2022</a> / </b><a href="https://arxiv.org/pdf/2204.04799.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/l2p">Code</a>
					<br><br>

					<h3>FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Timothy Dozat, Vincent Perot, Guolong Su, Nan Hua, Joshua Ainslie, Renshen Wang, Yasuhisa Fujii, Tomas Pfister<br>
					<b><a href="https://www.2022.aclweb.org/">ACL 2022</a> / </b><a href="https://arxiv.org/pdf/2203.08411.pdf">Paper</a> <b>/</b> <a href="https://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html">Google AI Blog</a>
					<br><br>

					<h3>Learning to Prompt for Continual Learning</h3>
					Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, Tomas Pfister<br>
					<b><a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> / </b><a href="https://arxiv.org/pdf/2112.08654.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/l2p">Code</a> <b>/</b> <a href="https://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html">Google AI Blog</a>
					<br><br>

					<h3>ROPE: Reading Order Equivariant Positional Encoding for Graph-based Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Chu Wang, Renshen Wang, Yasuhisa Fujii, Siyang Qin, Ashok Popat, Tomas Pfister<br>
					<b><a href="https://aclanthology.org/events/acl-2021/">ACL 2021</a> / </b><a href="https://arxiv.org/pdf/2106.10786.pdf">Paper</a> <h6>(Oral Presentation)</h6>
					<br><br>

					<h3>Learning to Branch for Multi-Task Learning</h3>
					Pengsheng Guo, Chen-Yu Lee, Daniel Ulbricht<br>
					<b><a href="https://icml.cc/Conferences/2020/">ICML 2020</a> / </b><a href="https://arxiv.org/pdf/2006.01895.pdf">Paper</a>
					<br><br>

					<h3>Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation</h3>
					Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, Daniel Ulbricht<br>
					<b><a href="http://cvpr2019.thecvf.com/">CVPR 2019</a> / </b><a href="https://arxiv.org/pdf/1903.04064.pdf">Paper</a> <b>/</b> <a href="https://github.com/apple/ml-cvpr2019-swd">Code</a> <b>/</b> <a href="https://machinelearning.apple.com/2019/06/15/bridging-the-domain-gap-for-neural-models.html"> ML Journal</a>
					<br><br>

					<h3>GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</h3>
					Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich<br>
					<b><a href="https://icml.cc/Conferences/2018/">ICML 2018</a> / </b><a href="https://arxiv.org/pdf/1711.02257.pdf">Paper</a>
					<br><br>

					<h3>RoomNet: End-to-End Room Layout Estimation</h3>
					Chen-Yu Lee, Vijay Badrinarayanan, Tomasz Malisiewicz, Andrew Rabinovich<br>
					<b><a href="http://iccv2017.thecvf.com/">ICCV 2017</a> / </b><a href="https://arxiv.org/pdf/1703.06241.pdf">Paper</a>
					<br><br>

					<h3>Recursive Recurrent Nets with Attention Modeling for OCR in the Wild</h3>
					Chen-Yu Lee and Simon Osindero<br>
					<b><a href="http://cvpr2016.thecvf.com/">CVPR 2016</a> / </b><a href="http://arxiv.org/pdf/1603.03101v1.pdf">Paper</a>
					<br><br>

					<h3>Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree</h3>
					Chen-Yu Lee, Patrick Gallagher, Zhuowen Tu<br>
					<b><a href="https://ieeexplore.ieee.org/document/7927440/">TPAMI 2017</a> / </b><a href="PDF/Lee_PAMI17.pdf">Paper</a><br>
					<b><a href="https://www.aistats.org/aistats2016/">AISTATS 2016</a> / </b><a href="http://arxiv.org/pdf/1509.08985v2.pdf">Paper</a> <b>/</b> <a href="https://github.com/chl260/general-pooling">Code</a>
					<br><br>					

					<h3>Deeply-Supervised Nets</h3>
					Chen-Yu Lee*, Saining Xie*, Patrick Gallagher, Zhengyou Zhang, Zhuowen Tu (*equal contribution)<br>
					<b><a href="https://www.aistats.org/aistats2015/">AISTATS 2015</a> / </b><a href="https://proceedings.mlr.press/v38/lee15a.pdf">Paper</a> <b>/</b> <a href="https://github.com/s9xie/DSN">Code</a> <b>(<a href="PDF/tta.jpg"><h6>Test of Time Award</h6></a> @ <a href="https://virtual.aistats.org/virtual/2025/poster/10054">AISTATS 2025</a>, <a href="PDF/dsn-aistats-testoftime.pdf">slides</a>)</b> <br>
					<b><a href="http://www.dlworkshop.org/accepted-papers/">NIPS 2014 DL Workshop</a> / </b><a href="http://arxiv.org/abs/1409.5185">Paper</a> <h6>(Oral Presentation)</h6>
					<br><br>

					<h3>Region-based Discriminative Feature Pooling for Scene Text Recognition</h3>
					Chen-Yu Lee, Anurag Bhardwaj, Wei Di, Vignesh Jagadeesh, Robinson Piramuthu<br>
					<b><a href="http://www.pamitc.org/cvpr14/">CVPR 2014</a> / </b><a href="PDF/Lee_CVPR14.pdf">Paper</a>
			</div>
		</section>
		
		<section>
			<div class="sectionTitle">
				<h1>Pre-Prints</h1>
			</div>
			
			<div class="sectionContent">																
					<h3>When One LLM Drools, Multi-LLM Collaboration Rules</h3>
					Shangbin Feng, Wenxuan Ding, Alisa Liu, Zifeng Wang, Weijia Shi, Yike Wang, Zejiang Shen, Xiaochuang Han, Hunter Lang, Chen-Yu Lee, Tomas Pfister, Yejin Choi, Yulia Tsvetkov<br>
					<b><a href="https://arxiv.org/">arXiv 2025</a> / </b><a href="https://arxiv.org/pdf/2502.04506">Paper</a> 
					<br><br>
									
					<h3>Universal Model Routing for Efficient LLM Inference</h3>
					Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Zifeng Wang, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, Sanjiv Kumar<br>
					<b><a href="https://arxiv.org/">arXiv 2025</a> / </b><a href="https://arxiv.org/pdf/2502.08773">Paper</a> 
					<br><br>

					<h3>Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems</h3>
					Shangbin Feng, Zifeng Wang, Palash Goyal, Yike Wang, Weijia Shi, Huang Xia, Hamid Palangi, Luke Zettlemoyer, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://arxiv.org/">arXiv 2025</a> / </b><a href="https://arxiv.org/pdf/2502.04510">Paper</a> 
					<br><br>

					<h3>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models</h3>
					Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister<br>
					<b><a href="https://arxiv.org/">arXiv 2023</a> / </b><a href="https://arxiv.org/pdf/2308.00675.pdf">Paper</a> 
					<br><br>

					<h3>A Simple Semi-Supervised Learning Framework for Object Detection</h3>
					Kihyuk Sohn*, Zizhao Zhang*, Chun-Liang Li, Han Zhang, Chen-Yu Lee, Tomas Pfister (*equal contribution)<br>
					<b><a href="https://arxiv.org/">arXiv 2020</a> / </b><a href="https://arxiv.org/pdf/2005.04757.pdf">Paper</a> <b> / </b> <a href="https://github.com/google-research/ssl_detection/">Code</a>
			</div>
		</section>	

		<section>
			<div class="sectionTitle">
				<h1>Awards</h1>
			</div>
			
			<div class="sectionContent">
					<b>Test-of-Time Award</b> at AISTATS 2025 <br>
					<b>Oral</b> at NAACL 2025 <br>
					<b>Google Spotlight Award</b> at ACL 2023 <br>
					<b>Oral</b> at ACL 2021 <br>
					<b>Oral</b> at NIPS 2014 DL workshop
			</div>
		</section>

		<section>
			<div class="sectionTitle">
				<h1>Academic Services</h1>
			</div>
			
			<div class="sectionContent">
				<article>
					<b>Area Chair:</b> NeurIPS 2025, ICLR 2026, ICLR 2025, ICLR 2024 <br>

					<b>Reviewer:</b> NeurIPS, ICML, ICLR, ACL, NAACL, EMNLP, COLM, CVPR, ICCV, ECCV, BMVC, PAMI, IJCV, JMLR <br>

					<b>Outstanding Reviewer:</b> CVPR 2019, BMVC 2019 <br>

					<b>Organizer / PC:</b> SIGKDD 2025 AI4SupplyChain, CVPR 2020 CV4AR/VR
				</article>
			</div>
			<div class="clear"></div>
		</section>

	</div>
</div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-3753241-1");
pageTracker._initData();
pageTracker._trackPageview();
</script>
</body>
</html>
