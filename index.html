<!DOCTYPE html>
<html>
<head>
<title>Chen-Yu Lee</title>

<meta name="viewport" content="width=device-width"/>
<meta name="description" content="Chen-Yu Lee."/>
<meta charset="UTF-8"> 

<link type="text/css" rel="stylesheet" href="style.css">
<link href='http://fonts.googleapis.com/css?family=Rokkitt:400,700|Lato:400,300' rel='stylesheet' type='text/css'>
<link rel="shortcut icon" href="favicon.ico" />

<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>
<body id="top">
<div id="cv">
	<div class="mainDetails">
		<div id="headshot">
			<img src="me3.JPG" alt="Chen-Yu Lee" /></a>
		</div>
		
		<div id="name">
			<h2>Chen-Yu Lee</h2><br><br>
			<div id="contactDetails">
				<ul>
					<!--<li align="left"><a href="PDF/ChenYuLee_CV.pdf">CV</a>-->
					<br>
					<li align="left">
						<a href="mailto:chenyulee@google.com">Email</a>	
						 / 
						<a href="https://scholar.google.com/citations?user=uWPUSEgAAAAJ&hl=en">Google Scholar</a>	
				</ul>
			</div>
		</div>
	</div>
	<br><br><br><br><br><br><br>
	<div id="mainArea">
		<section>
			<div class="sectionContent">
				<h4>
					I am currently a Staff Research Scientist and Manager at Google Cloud AI Research, working on machine learning and its real-world applications across various tasks and modalities.<br><br>
				</h4>
				<h5>
					Previously I was at Apple where I published the first research <a href="https://machinelearning.apple.com/2019/06/15/bridging-the-domain-gap-for-neural-models.html">paper</a> from the Technology Development Group at CVPR and launched several key features in <a href="https://developer.apple.com/augmented-reality/arkit/">ARKit</a>. I was also in the AI Research Group at Magic Leap with <a href="https://scholar.google.com/citations?user=yOcNQVgAAAAJ&hl=en">Andrew Rabinovich</a>. I did my PhD in deep learning, advised by Professors <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a> and <a href="http://code.ucsd.edu/~pcosman/">Pamela Cosman</a> at UC San Diego, and advised by <a href="https://scholar.google.com/citations?user=Jq8ZS5kAAAAJ&hl=en">Simon Osindero</a> during the summer.<br><br>
				</h5>
				<h5>
					We are building a world-class team to explore the intersection of large AI models and high-value enterprise AI challenges. Contact me for more details.
				</h5>				
			</div>
		</section>

		<section>
			<div class="sectionTitle">
				<h1>Publications</h1>
			</div>
			
			<div class="sectionContent">
					<h3>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes</h3>
					Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2305.02301.pdf">Paper</a> (Findings) <b>/</b> <a href="https://github.com/google-research/distilling-step-by-step">Code</a> <b>/</b> <a href="https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html">Google AI Blog</a> <b><a href="https://blog.research.google/2023/07/google-at-acl-2023.html">(Google ACL 2023 Spotlight)</a></b>
					<br><br>

					<h3>QueryForm: A Simple Zero-shot Form Entity Query Framework</h3>
					Zifeng Wang, Zizhao Zhang, Jacob Devlin, Chen-Yu Lee, Guolong Su, Hao Zhang, Jennifer Dy, Vincent Perot, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2211.07730.pdf">Paper</a> (Findings)
					<br><br>

					<h3>FormNetV2: Multimodal Graph Contrastive Learning for Form Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Hao Zhang, Timothy Dozat, Vincent Perot, Guolong Su, Xiang Zhang, Kihyuk Sohn, Nikolai Glushnev, Renshen Wang, Joshua Ainslie, Shangbang Long, Siyang Qin, Yasuhisa Fujii, Nan Hua, Tomas Pfister<br>
					<b><a href="https://2023.aclweb.org/">ACL 2023</a> / </b><a href="https://arxiv.org/pdf/2305.02549.pdf">Paper</a>
					<br><br>									

					<h3>Multimodal Prompting with Missing Modalities for Visual Recognition</h3>
					Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu, Chen-Yu Lee<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2303.03369.pdf">Paper</a> <b>/</b> <a href="https://github.com/YiLunLee/Missing_aware_prompts">Code</a>
					<br><br>

					<h3>Pic2Word: Mapping Pictures to Words for Zero-shot Composed Image Retrieval</h3>
					Kuniaki Saito, Kihyuk Sohn, Xiang Zhang, Chun-Liang Li, Chen-Yu Lee, Kate Saenko, Tomas Pfister<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2302.03084.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/composed_image_retrieval">Code</a>  <b>/</b> <a href="https://blog.research.google/2023/07/pic2word-mapping-pictures-to-words-for.html">Google AI Blog</a>
					<br><br>

					<h3>Prefix Conditioning Unifies Language and Label Supervision</h3>
					Kuniaki Saito, Kihyuk Sohn, Xiang Zhang, Chun-Liang Li, Chen-Yu Lee, Kate Saenko, Tomas Pfister<br>
					<b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> / </b><a href="https://arxiv.org/pdf/2206.01125.pdf">Paper</a>  <b>/</b> <a href="https://blog.research.google/2023/06/unifying-image-caption-and-image.html">Google AI Blog</a>
					<br><br>

					<h3>Neural Spline Search for Quantile Probabilistic Modeling</h3>
					Ruoxi Sun, Chun-Liang Li, Sercan O. Arik, Michael W. Dusenberry, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://aaai-23.aaai.org/">AAAI 2023</a> / </b><a href="https://arxiv.org/pdf/2301.04857.pdf">Paper</a>
					<br><br>					

					<h3>Unifying Distribution Alignment as a Loss for Imbalanced Semi-Supervised Learning</h3>
					Justin Lazarow, Kihyuk Sohn, Chen-Yu Lee, Chun-Liang Li, Zizhao Zhang, Tomas Pfister<br>
					<b><a href="https://wacv2023.thecvf.com/">WACV 2023</a> / </b><a href="https://openaccess.thecvf.com/content/WACV2023/papers/Lazarow_Unifying_Distribution_Alignment_as_a_Loss_for_Imbalanced_Semi-Supervised_Learning_WACV_2023_paper.pdf">Paper</a>
					<br><br>

					<h3>Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types</h3>
					Kihyuk Sohn, Jinsung Yoon, Chun-Liang Li, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://wacv2023.thecvf.com/">WACV 2023</a> / </b><a href="https://arxiv.org/pdf/2112.11573.pdf">Paper</a>
					<br><br>

					<h3>Self-supervise, Refine, Repeat: Improving Unsupervised Anomaly Detection</h3>
					Jinsung Yoon, Kihyuk Sohn, Chun-Liang Li, Sercan O Arik, Chen-Yu Lee, Tomas Pfister<br>
					<b><a href="https://www.jmlr.org/tmlr/">TMLR 2022</a> / </b><a href="https://arxiv.org/pdf/2106.06115.pdf">Paper</a>
					<br><br>

					<h3>DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</h3>
					Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, Tomas Pfister<br>
					<b><a href="https://eccv2022.ecva.net/">ECCV 2022</a> / </b><a href="https://arxiv.org/pdf/2204.04799.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/l2p">Code</a>
					<br><br>

					<h3>FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Timothy Dozat, Vincent Perot, Guolong Su, Nan Hua, Joshua Ainslie, Renshen Wang, Yasuhisa Fujii, Tomas Pfister<br>
					<b><a href="https://www.2022.aclweb.org/">ACL 2022</a> / </b><a href="https://arxiv.org/pdf/2203.08411.pdf">Paper</a> <b>/</b> <a href="https://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html">Google AI Blog</a>
					<br><br>

					<h3>Learning to Prompt for Continual Learning</h3>
					Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, Tomas Pfister<br>
					<b><a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> / </b><a href="https://arxiv.org/pdf/2112.08654.pdf">Paper</a> <b>/</b> <a href="https://github.com/google-research/l2p">Code</a> <b>/</b> <a href="https://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html">Google AI Blog</a>
					<br><br>

					<h3>Learning from Weakly-labeled Web Videos via Exploring Sub-Concepts</h3>
					Kunpeng Li, Zizhao Zhang, Guanhang Wu, Xuehan Xiong, Chen-Yu Lee, Zhichao Lu, Yun Fu, Tomas Pfister<br>
					<b><a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a> / </b><a href="https://arxiv.org/pdf/2101.03713.pdf">Paper</a> <b>/</b> <a href="https://ai.googleblog.com/2022/03/learning-from-weakly-labeled-videos-via.html">Google AI Blog</a>
					<br><br>

					<h3>ROPE: Reading Order Equivariant Positional Encoding for Graph-based Document Information Extraction</h3>
					Chen-Yu Lee, Chun-Liang Li, Chu Wang, Renshen Wang, Yasuhisa Fujii, Siyang Qin, Ashok Popat, Tomas Pfister<br>
					<b><a href="https://aclanthology.org/events/acl-2021/">ACL 2021</a> / </b><a href="https://arxiv.org/pdf/2106.10786.pdf">Paper</a> <b>(Oral Presentation)</b>
					<br><br>

					<h3>Learning to Branch for Multi-Task Learning</h3>
					Pengsheng Guo, Chen-Yu Lee, Daniel Ulbricht<br>
					<b><a href="https://icml.cc/Conferences/2020/">ICML 2020</a> / </b><a href="https://arxiv.org/pdf/2006.01895.pdf">Paper</a>
					<br><br>

					<h3>Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation</h3>
					Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, Daniel Ulbricht<br>
					<b><a href="http://cvpr2019.thecvf.com/">CVPR 2019</a> / </b><a href="https://arxiv.org/pdf/1903.04064.pdf">Paper</a> <b>/</b> <a href="https://github.com/apple/ml-cvpr2019-swd">Code</a> <b>/</b> <a href="https://machinelearning.apple.com/2019/06/15/bridging-the-domain-gap-for-neural-models.html"> ML Journal</a>
					<br><br>

					<h3>GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</h3>
					Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich<br>
					<b><a href="https://icml.cc/Conferences/2018/">ICML 2018</a> / </b><a href="https://arxiv.org/pdf/1711.02257.pdf">Paper</a>
					<br><br>

					<h3>RoomNet: End-to-End Room Layout Estimation</h3>
					Chen-Yu Lee, Vijay Badrinarayanan, Tomasz Malisiewicz, Andrew Rabinovich<br>
					<b><a href="http://iccv2017.thecvf.com/">ICCV 2017</a> / </b><a href="https://arxiv.org/pdf/1703.06241.pdf">Paper</a>
					<br><br>

					<h3>Generalizing Pooling Functions in CNNs: Mixed, Gated, and Tree</h3>
					Chen-Yu Lee, Patrick Gallagher, Zhuowen Tu<br>
					<b><a href="https://ieeexplore.ieee.org/document/7927440/">TPAMI 2017</a> / </b><a href="PDF/Lee_PAMI17.pdf">Paper</a>
					<br><br>

					<h3>Recursive Recurrent Nets with Attention Modeling for OCR in the Wild</h3>
					Chen-Yu Lee and Simon Osindero<br>
					<b><a href="http://cvpr2016.thecvf.com/">CVPR 2016</a> / </b><a href="http://arxiv.org/pdf/1603.03101v1.pdf">Paper</a>
					<br><br>

					<h3>Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree</h3>
					Chen-Yu Lee, Patrick Gallagher, Zhuowen Tu<br>
					<b><a href="https://www.aistats.org/aistats2016/">AISTATS 2016</a> / </b><a href="http://arxiv.org/pdf/1509.08985v2.pdf">Paper</a> <b>/</b> <a href="https://github.com/chl260/general-pooling">Code</a>
					<br><br>					

					<h3>Deeply-Supervised Nets</h3>
					Chen-Yu Lee*, Saining Xie*, Patrick Gallagher, Zhengyou Zhang, Zhuowen Tu (*equal contribution)<br>
					<b><a href="https://www.aistats.org/aistats2015/">AISTATS 2015</a> / </b><a href="PDF/Lee_AISTATS15.pdf">Paper</a> <b>/</b> <a href="https://github.com/s9xie/DSN">Code</a><br>
					<b><a href="http://www.dlworkshop.org/accepted-papers/">NIPS 2014 Workshop</a> / </b><a href="http://arxiv.org/abs/1409.5185">Paper</a> <b>(Oral Presentation)</b>
					<br><br>

					<h3>Region-based Discriminative Feature Pooling for Scene Text Recognition</h3>
					Chen-Yu Lee, Anurag Bhardwaj, Wei Di, Vignesh Jagadeesh, Robinson Piramuthu<br>
					<b><a href="http://www.pamitc.org/cvpr14/">CVPR 2014</a> / </b><a href="PDF/Lee_CVPR14.pdf">Paper</a>
					<br><br>	
					
					<h3>Tracking Epithelial Cell Junctions in C. elegans Embryogenesis with Active Contours Guided by SIFT Flow</h3>
					Sukryool Kang, Chen-Yu Lee, Monira Goncalves, Andrew Chisholm, Pamela Cosman<br>
					<b><a href="https://ieeexplore.ieee.org/document/6803854/">TBME 2014</a> / </b><a href="PDF/Lee_TBME14.pdf">Paper</a>
					<br><br>

					<h3>Automated Cell Junction Tracking with Modified Active Contours Guided by SIFT Flow</h3>
					Chen-Yu Lee, Sukryool Kang, Andrew Chisholm, Pamela Cosman<br>
					<b><a href="https://ieeexplore.ieee.org/document/6867866/">ISBI 2014</a> / </b><a href="PDF/Lee_ISBI14.pdf">Paper</a> <b> / </b> <a href="http://youtu.be/174-tlPX9Iw">Demo</a>
					<br><br>
				
					<h3>Smoke Detection Using Spatial and Temporal Analyses</h3>
					Chen-Yu Lee, Chin-Teng Lin, Chao-Ting Hong, Miin-Tsair Su<br>
					<b><a href="http://www.ijicic.net/ijicic/">IJICIC 2012</a> / </b><a href="PDF/IJICIC-11-03010.pdf">Paper</a>
					<br><br>
				
					<h3>Spatio‐temporal Analysis in Smoke Detection</h3>
					Chen-Yu Lee, Chin‐Teng Lin, Chao‐Ting Hong<br>
					<b><a href="https://ieeexplore.ieee.org/document/5478724/">ICSIPA 2009</a> / </b><a href="PDF/ICSIPA-09-smoke.pdf">Paper</a> <b> / </b> <a href="https://sites.google.com/site/sduspa/">Project Page</a>
					<br>
			</div>
		</section>
		
		<section>
			<div class="sectionTitle">
				<h1>Pre-Prints & Tech Reports</h1>
			</div>
			
			<div class="sectionContent">
					<h3>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models</h3>
					Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister<br>
					<b><a href="https://arxiv.org/">arXiv 2023</a> / </b><a href="https://arxiv.org/pdf/2308.00675.pdf">Paper</a> 
					<br><br>

					<h3>A Simple Semi-Supervised Learning Framework for Object Detection</h3>
					Kihyuk Sohn*, Zizhao Zhang*, Chun-Liang Li, Han Zhang, Chen-Yu Lee, Tomas Pfister (*equal contribution)<br>
					<b><a href="https://arxiv.org/">arXiv 2020</a> / </b><a href="https://arxiv.org/pdf/2005.04757.pdf">Paper</a> <b> / </b> <a href="https://github.com/google-research/ssl_detection/">Code</a>
					<br><br>

					<h3>Training Deeper Convolutional Networks with Deep Supervision</h3>
					Liwei Wang, Chen-Yu Lee, Zhuowen Tu, Svetlana Lazebnik<br>
					<b><a href="https://arxiv.org/">arXiv 2015</a> / </b><a href="http://arxiv.org/pdf/1505.02496v1.pdf">Paper</a> <b> / </b> <a href="https://github.com/lwwang/Places_CNDS_model">Code</a> <b> / </b> <a href="http://places.csail.mit.edu/user/leaderboard.php">Leaderboard of MIT Place205</a>
					<br>
			</div>
		</section>	
		
		<section>
			<div class="sectionTitle">
				<h1>Academic Services</h1>
			</div>
			
			<div class="sectionContent">
				<article>
					<b>Area Chair:</b> ICLR 2024 <br>

					<b>Reviewer:</b> CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, BMVC, PAMI, IJCV, JMLR, TIP, TNNLS <br>

					<b>Outstanding Reviewer:</b> CVPR 2019, BMVC 2019 <br>

					<b>Program Committee Member:</b> Computer Vision for AR/VR Workshop at CVPR 2020
				</article>
			</div>
			<div class="clear"></div>
		</section>

	</div>
</div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-3753241-1");
pageTracker._initData();
pageTracker._trackPageview();
</script>
</body>
</html>
